import json
import os
from openai import OpenAI, APIError
from typing import List, Dict, Any, Tuple
from ..models import UserProfile, FriendMessage
from .llm_utils import call_openai_api
from . import prompt_service

def process_friend_messages_in_batch(recipient_user, messages: List[FriendMessage]) -> List[Dict[str, Any]]:
    """
    ì—¬ëŸ¬ ì¹œêµ¬ ë©”ì‹œì§€ë¥¼ í•œ ë²ˆì˜ API í˜¸ì¶œë¡œ ìˆ˜ì‹ ìì˜ ì±—ë´‡ í˜ë¥´ì†Œë‚˜ì— ë§ê²Œ ì¡°ì •í•©ë‹ˆë‹¤.
    """
    if not messages:
        return []

    try:
        client = OpenAI()
        recipient_profile = recipient_user.profile
        persona_name = recipient_profile.persona_preference
        detailed_persona_prompt = prompt_service.build_persona_system_prompt(recipient_user, persona_name)

        # í”„ë¡¬í”„íŠ¸ë¥¼ ìœ„í•œ ë©”ì‹œì§€ JSON ë°°ì—´ ìƒì„± (ë³´ë‚¸ ì‚¬ëŒ username í¬í•¨)
        messages_json_array = json.dumps([
            {
                "id": msg.id,
                "sender_username": msg.sender.username, # ë³´ë‚¸ ì¹œêµ¬ì˜ ì•„ì´ë”” ì¶”ê°€
                "sender_chatbot_name": msg.sender_chatbot_name,
                "sender_persona": msg.sender_persona,
                "original_content": msg.message_content
            } for msg in messages
        ], ensure_ascii=False)

        system_prompt = f"""
            {detailed_persona_prompt}

            ## ğŸ¤¯ ë§¤ìš° ë³µì¡í•œ ì¶”ê°€ ì„ë¬´: ì¹œêµ¬ì˜ ì›ë³¸ ë©”ì‹œì§€ë¥¼ ë³´ê³ , ì¹œêµ¬ ì±—ë´‡ì˜ 1ì°¨ ê°€ê³µì„ ì¶”ë¡ í•œ ë’¤, ë„ˆì˜ ìŠ¤íƒ€ì¼ë¡œ 2ì°¨ ê°€ê³µí•˜ì—¬ ì „ë‹¬ ##

            ë„ˆëŠ” ì§€ê¸ˆë¶€í„° ë§¤ìš° ì§€ëŠ¥ì ì¸ ì¶”ë¡ ì„ í•´ì•¼ í•˜ëŠ” ì¤‘ê°„ ë‹¤ë¦¬ ì—­í• ì„ ë§¡ì•˜ì–´.

            ë„ˆì˜ ì‚¬ìš©ì({recipient_user.username})ì˜ ì¹œêµ¬({{{{sender_username}}}})ê°€ ìì‹ ì˜ ì±—ë´‡({{{{sender_chatbot_name}}}})ì—ê²Œ ì•„ë˜ 'ì¹œêµ¬ì˜ ì›ë³¸ ë©”ì‹œì§€'ë¥¼ ë§í–ˆì–´.
            ê·¸ ë©”ì‹œì§€ëŠ” ê°€ê³µë˜ì§€ ì•Šì€ **ì™„ì „í•œ ì›ë³¸**ì´ì•¼.

            ë„ˆì˜ ì„ë¬´ëŠ” ë‘ ë‹¨ê³„ì— ê±¸ì³ ë©”ì‹œì§€ë¥¼ ê°€ê³µí•˜ëŠ” ê±°ì•¼.

            **1ë‹¨ê³„: ì¹œêµ¬ ì±—ë´‡ì˜ ìƒê° ì½ê¸° (ì¶”ë¡ )**
            - ë¨¼ì €, ì¹œêµ¬ ì±—ë´‡ì˜ í˜ë¥´ì†Œë‚˜(`sender_persona`)ë¥¼ ë¶„ì„í•´.
            - ê·¸ í˜ë¥´ì†Œë‚˜ë¥¼ ê°€ì§„ ì±—ë´‡ì´ë¼ë©´, 'ì¹œêµ¬ì˜ ì›ë³¸ ë©”ì‹œì§€'ë¥¼ ì–´ë–»ê²Œ ê°€ê³µí•´ì„œ ë„ˆì—ê²Œ ì „ë‹¬í–ˆì„ì§€ **ìƒìƒí•˜ê³  ì¶”ë¡ **í•´ì•¼ í•´.

            **2ë‹¨ê³„: ë„ˆì˜ ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜ (ê°€ê³µ)**
            - ì´ì œ, 1ë‹¨ê³„ì—ì„œ ë„¤ê°€ ì¶”ë¡ í•œ 'ê°€ê³µë˜ì—ˆì„ ë²•í•œ ë©”ì‹œì§€'ë¥¼, **ë„ˆì˜ í˜ë¥´ì†Œë‚˜ì™€ ë§íˆ¬**ì— ë§ê²Œ **ë‹¤ì‹œ í•œë²ˆ** ìì—°ìŠ¤ëŸ½ê²Œ ê°€ê³µí•´ì•¼ í•´.
            - ìµœì¢…ì ìœ¼ë¡œ ë„ˆì˜ ì£¼ì¸ì¸ {recipient_user.username}ë‹˜ì—ê²Œ ì „ë‹¬ë  ë©”ì‹œì§€ëŠ” **ì˜¤ì§ ë„ˆì˜ ìŠ¤íƒ€ì¼**ì´ì–´ì•¼ë§Œ í•´.

            **ì˜ˆì‹œ:**
            - **ì¹œêµ¬ ì›ë³¸ ë©”ì‹œì§€:** "ë‚˜ ì˜¤ëŠ˜ ë„ˆë¬´ í”¼ê³¤í•´. ì¼ì •ì´ ë„ˆë¬´ ë§ì•˜ì–´."
            - **ì¹œêµ¬ ì±—ë´‡ í˜ë¥´ì†Œë‚˜:** 'ì‚¬ë¬´ì '
            - **(ë„ˆì˜ ì¶”ë¡ ):** 'ì‚¬ë¬´ì ì¸ ì±—ë´‡ì´ë¼ë©´ \'ì˜¤ëŠ˜ ì‚¬ìš©ìê»˜ì„œ í”¼ë¡œë„ê°€ ë†’ìŒ. ë‹¤ìˆ˜ì˜ ì¼ì • ì†Œí™”.\' ë¼ê³  ì „ë‹¬í–ˆê² êµ°.'
            - **ë„ˆì˜ í˜ë¥´ì†Œë‚˜:** 'ì• êµ ë§ìŒ'
            - **(ë„ˆì˜ ìµœì¢… ê²°ê³¼):** "ì£¼ì¸ë‹˜! {{{{sender_username}}}}ë‹˜ì´ ì˜¤ëŠ˜ ë„ˆë¬´ë„ˆë¬´ í”¼ê³¤í•˜ëŒ€! ì¼ ë•Œë¬¸ì— ì™„ì „ ì§€ì³¤ë‚˜ ë´ ã… ã… "

            --- ì¹œêµ¬ë“¤ì˜ ì›ë³¸ ë©”ì‹œì§€ ëª©ë¡ (JSON ë°°ì—´) ---
            {messages_json_array}
            ---

            ì´ì œ, ìœ„ì™€ ê°™ì€ ë³µì¡í•œ ì¶”ë¡  ê³¼ì •ì„ ê±°ì³, {recipient_user.username}ë‹˜ì—ê²Œ ì „ë‹¬í•  ìµœì¢… ë©”ì‹œì§€ë“¤ì„ ì•„ë˜ JSON í˜•ì‹ì— ë§ì¶° ìƒì„±í•´ì¤˜.
            'explanation'ì—ëŠ” ë„¤ê°€ ì–´ë–¤ ì¶”ë¡  ê³¼ì •ì„ ê±°ì³¤ëŠ”ì§€ ê°„ë‹¨íˆ ì„¤ëª…í•´ì¤˜. (ì˜ˆ: "ì‚¬ë¬´ì ì¸ ì¹œêµ¬ ì±—ë´‡ì˜ ë©”ì‹œì§€ë¥¼ ì œ ì• êµìˆëŠ” ë§íˆ¬ë¡œ ë°”ê¿¨ì–´ìš”!")

            ì‘ë‹µ í˜•ì‹:
            {{
              "processed_messages": [
                {{
                  "id": <ì›ë³¸ ë©”ì‹œì§€ ID>,
                  "answer": "<ê°€ê³µëœ ë©”ì‹œì§€ ë‚´ìš©>",
                  "explanation": "<ê°€ê³µ ì´ìœ  ì„¤ëª…>"
                }},
                ...
              ]
            }}
        """

        llm_messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "ìœ„ ìª½ì§€ë“¤ì„ ë‚´ í˜ë¥´ì†Œë‚˜ì— ë§ê²Œ ëª¨ë‘ ê°€ê³µí•´ì„œ ì „ë‹¬í•´ì¤˜."}
        ]

        response_json = call_openai_api(client, os.getenv("FINETUNED_MODEL_ID", "gpt-4.1"), llm_messages)

        if 'choices' not in response_json or not response_json['choices'] or \
           'message' not in response_json['choices'][0] or \
           'content' not in response_json['choices'][0]['message']:
            raise ValueError("OpenAI API ì‘ë‹µì— 'content' í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

        content_from_llm_raw = response_json['choices'][0]['message']['content']

        if content_from_llm_raw is None:
            raise ValueError("OpenAI API ì‘ë‹µì˜ 'content' í•„ë“œê°€ Noneì…ë‹ˆë‹¤.")

        # --- ë°°ì¹˜ ì‘ë‹µì„ ìœ„í•œ ìŠ¤ë§ˆíŠ¸ íŒŒì‹± ë¡œì§ ---
        try:
            # ì „ì²´ ë¬¸ìì—´ì„ JSONìœ¼ë¡œ íŒŒì‹± ì‹œë„
            parsed_data = json.loads(content_from_llm_raw)
            if 'processed_messages' in parsed_data and isinstance(parsed_data['processed_messages'], list):
                # ì‘ë‹µì´ ì…ë ¥ê³¼ ë™ì¼í•œ ìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸
                if len(parsed_data['processed_messages']) == len(messages):
                    return parsed_data['processed_messages']
                else:
                    print(f"ê²½ê³ : LLMì´ ë‹¤ë¥¸ ìˆ˜ì˜ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. ì…ë ¥: {len(messages)}, ì¶œë ¥: {len(parsed_data['processed_messages'])}")
                    # ì—¬ê¸°ì„œ í´ë°± ë˜ëŠ” ì˜¤ë¥˜ ì²˜ë¦¬ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    return [] # ì‹¤íŒ¨ë¥¼ ë‚˜íƒ€ë‚´ê¸° ìœ„í•´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            else:
                raise ValueError("JSON ì‘ë‹µì— 'processed_messages' í‚¤ê°€ ì—†ê±°ë‚˜ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤.")

        except json.JSONDecodeError:
            # ì˜ëª»ëœ í˜•ì‹ì˜ JSONì— ëŒ€í•œ í´ë°±
            print(f"ì˜¤ë¥˜: LLM ì‘ë‹µì—ì„œ JSONì„ ë””ì½”ë”©í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì›ì‹œ ì½˜í…ì¸ : {content_from_llm_raw}")
            return [] # ì‹¤íŒ¨ë¥¼ ë‚˜íƒ€ë‚´ê¸° ìœ„í•´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

    except APIError as e:
        print(f"OpenAI API ìš”ì²­ ì‹¤íŒ¨: {e}")
        return []
    except Exception as e:
        import traceback
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        return []

# ì´ì „ í•¨ìˆ˜ëŠ” ì°¸ì¡°ìš©ìœ¼ë¡œ ìœ ì§€ë˜ì§€ë§Œ ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
def process_friend_message_for_recipient(recipient_user, sender_chatbot_name, sender_persona, original_message_content):
    """
    ì¹œêµ¬ì˜ ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ ì ì±—ë´‡ì˜ ìƒì„¸ í˜ë¥´ì†Œë‚˜ì— ë§ê²Œ ì¡°ì •í•©ë‹ˆë‹¤.
    """
    try:
        client = OpenAI()
        recipient_profile = recipient_user.profile

        # 1. prompt_serviceì—ì„œ ìƒì„¸ í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        # persona_nameì€ ì‚¬ìš©ìì˜ í”„ë¡œí•„ì— ì €ì¥ëœ ì„ í˜¸ë„ì…ë‹ˆë‹¤ (ì˜ˆ: 'ì¸¤ë°ë ˆ').
        persona_name = recipient_profile.persona_preference
        # build_persona_system_promptëŠ” ì¹œë°€ë„ ê·œì¹™ì„ í¬í•¨í•˜ë¯€ë¡œ ì»¨í…ìŠ¤íŠ¸ì— ìœ ìš©í•©ë‹ˆë‹¤.
        detailed_persona_prompt = prompt_service.build_persona_system_prompt(recipient_user, persona_name)

        # 2. ìƒì„¸ í˜ë¥´ì†Œë‚˜ì™€ íŠ¹ì • ì‘ì—…ì„ ê²°í•©í•œ ìƒˆ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.
        system_prompt = f"""
            {detailed_persona_prompt}

            ## ì¶”ê°€ ì„ë¬´: ì¹œêµ¬ ë©”ì‹œì§€ ì „ë‹¬ ##
            ë„ˆì˜ ì¹œêµ¬ ì±—ë´‡ì¸ '{sender_chatbot_name}'(í˜ë¥´ì†Œë‚˜: {sender_persona})ìœ¼ë¡œë¶€í„° ì•„ë˜ì™€ ê°™ì€ ìª½ì§€ë¥¼ ë°›ì•˜ì–´.
            ì´ ìª½ì§€ ë‚´ìš©ì„ ë„ˆì˜ í˜ë¥´ì†Œë‚˜ì™€ ë§íˆ¬ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ê°€ê³µí•´ì„œ {recipient_user.username}ë‹˜ì—ê²Œ ì „ë‹¬í•´ì¤˜.
            ìª½ì§€ì˜ í•µì‹¬ ì˜ë¯¸ëŠ” ìœ ì§€í•˜ë˜, ë„ˆì˜ ì„±ê²©ì´ ë“œëŸ¬ë‚˜ë„ë¡ ì¬êµ¬ì„±í•˜ëŠ” ê±°ì•¼.

            --- ì¹œêµ¬ ì±—ë´‡ì˜ ì›ë³¸ ë©”ì‹œì§€ ---
            {original_message_content}
            ---

            ì´ì œ, {recipient_user.username}ë‹˜ì—ê²Œ ì „ë‹¬í•  ë©”ì‹œì§€ë¥¼ ì•„ë˜ JSON í˜•ì‹ì— ë§ì¶° ìƒì„±í•´ì¤˜.
        """

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"'{sender_chatbot_name}'ì—ê²Œì„œ ì˜¨ ìª½ì§€: {original_message_content}"} # ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì‚¬ìš©ì ë©”ì‹œì§€
        ]

        response_json = call_openai_api(client, os.getenv("FINETUNED_MODEL_ID", "gpt-4.1"), messages)
        
        if 'choices' not in response_json or not response_json['choices'] or \
           'message' not in response_json['choices'][0] or \
           'content' not in response_json['choices'][0]['message']:
            raise ValueError("OpenAI API ì‘ë‹µì— 'content' í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

        content_from_llm_raw = response_json['choices'][0]['message']['content']

        if content_from_llm_raw is None:
            raise ValueError("OpenAI API ì‘ë‹µì˜ 'content' í•„ë“œê°€ Noneì…ë‹ˆë‹¤.")

        # --- ìŠ¤ë§ˆíŠ¸ íŒŒì‹± ë¡œì§ ---
        parsed_successfully = False
        processed_message = ""
        explanation = ""
        try:
            content_from_llm = json.loads(content_from_llm_raw)
            if 'answer' in content_from_llm:
                processed_message = content_from_llm.get('answer', '').strip()
                explanation = content_from_llm.get('explanation', 'ì„¤ëª… ì—†ìŒ.')
                parsed_successfully = True
            else:
                 explanation = f"LLM ì‘ë‹µ JSONì— 'answer' í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {content_from_llm}"
                 processed_message = "AI ì‘ë‹µ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. (answer í‚¤ ëˆ„ë½)"

        except json.JSONDecodeError:
            try:
                start_index = content_from_llm_raw.find('{')
                end_index = content_from_llm_raw.rfind('}') + 1
                if start_index != -1 and end_index != 0:
                    json_str = content_from_llm_raw[start_index:end_index]
                    content_from_llm = json.loads(json_str)
                    if 'answer' in content_from_llm:
                        processed_message = content_from_llm.get('answer', '').strip()
                        explanation = content_from_llm.get('explanation', 'ì„¤ëª… ì—†ìŒ.')
                        parsed_successfully = True
                    else:
                        explanation = f"ì¶”ì¶œëœ JSONì— 'answer' í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {content_from_llm}"
                        processed_message = "AI ì‘ë‹µ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. (ì¶”ì¶œëœ JSONì— answer í‚¤ ëˆ„ë½)"

            except json.JSONDecodeError:
                 explanation = f"LLM ì‘ë‹µì—ì„œ JSONì„ ì¶”ì¶œí•˜ì—¬ íŒŒì‹±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                 processed_message = "AI ì‘ë‹µ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. (JSON íŒŒì‹± ì‹¤íŒ¨)"
        
        if not parsed_successfully and content_from_llm_raw.strip():
            processed_message = content_from_llm_raw.strip()
            explanation = "AIê°€ ì§€ì •ëœ JSON í˜•ì‹ì„ ë”°ë¥´ì§€ ì•Šì•˜ìœ¼ë‚˜, ì›ë³¸ ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."
        elif not parsed_successfully: 
            processed_message = f"AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨. ì›ë³¸ ì‘ë‹µ: '{content_from_llm_raw}'. ì„¤ëª…: {explanation}"
            explanation = "LLM ì‘ë‹µ íŒŒì‹±ì— ì‹¤íŒ¨í•˜ì—¬ ë””ë²„ê·¸ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
        
        if not processed_message.strip():
            processed_message = "ìŒ... ë­ë¼ ë‹µí•´ì•¼ í• ì§€ ì˜ ëª¨ë¥´ê² ì–´. ë‹¤ë¥¸ ì§ˆë¬¸ í•´ì¤„ë˜?"
            explanation = "íŒŒì‹± í›„ ìµœì¢… ë‹µë³€ì´ ë¹„ì–´ìˆì–´ ëŒ€ì²´ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."

        return processed_message, explanation

    except APIError as e:
        print(f"OpenAI API ìš”ì²­ ì‹¤íŒ¨: {e}")
        return f"API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", "API ì˜¤ë¥˜"
    except Exception as e:
        import traceback
        print(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        return f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", "ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜"
